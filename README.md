# ğŸ¤– Multi-Modal Sentiment and Emotion Classification

This project presents a deep learning system that classifies both **emotion** and **sentiment** from paired **image and text** inputs using a combination of computer vision and natural language processing techniques. It fuses signals from both modalities to achieve high performance on real-world affective content â€” especially in social media contexts.

---

## ğŸ§  Overview

Traditional models analyze image and text separately, often missing cross-modal emotional signals. This project fuses them using:

- âœ… Three CNNs trained on facial emotion datasets
- âœ… A DistilBERT model trained on tweet sentiment data
- âœ… A fusion MLP that combines both outputs
- âœ… A **Gradio interface** that displays predictions and confidence levels interactively

---

## ğŸ“š Datasets Used

| Dataset       | Modality | Description                                     |
|---------------|----------|-------------------------------------------------|
| FER-2013      | Image    | Grayscale facial expressions                    |
| RAF-DB        | Image    | Real-world affective faces                      |
| FER+          | Image    | Enhanced FER with crowd-validated labels        |
| Sentiment140  | Text     | 1.6M tweets labeled for positive/negative sentiment |

---

## ğŸ”§ Architecture

- ğŸ–¼ï¸ **CNNs**: Trained independently on FER-2013, RAF-DB, FER+
- ğŸ’¬ **DistilBERT**: Fine-tuned on Sentiment140 for sentiment detection
- ğŸ”— **Fusion Layer (MLP)**: Combines outputs from CNNs + BERT to produce joint classification
- ğŸ›ï¸ **Gradio UI**: Interactive gallery shows predictions, confidence scores, and ground truths

---

## ğŸ“Š Results

| Metric            | Score Range |
|-------------------|-------------|
| Emotion Accuracy  | Up to **95%** |
| Sentiment Accuracy| **82%â€“95%** |
| Fusion Accuracy   | Estimated **88.5%â€“92.5%** |

---

## ğŸš€ Running the Demo

1. Open: `MultiModalModelBrendon.ipynb` in **Google Colab** or **Jupyter Notebook**
2. Follow all cell blocks to:
   - Load models and preprocess input
   - Fuse image and text streams
   - Launch the Gradio interface
3. View a scrollable gallery of image-caption predictions and confidence charts

> â— **Note**: Large pretrained models are not included in this repo. Download links below.

---

## ğŸ“¦ Model Downloads

| Model                        | Download Link |
|-----------------------------|----------------|
| Fusion Emotion & Sentiment Model | [Google Drive Link ğŸ”—](https://drive.google.com/file/d/1Pp9Vy1gNAJhTtugsFnHExmjKhhAzulBo/view?usp=sharing) |
| FER2013 CNN Model            | [Google Drive Link ğŸ”—](https://drive.google.com/file/d/1IT27LIiKd8LptksYkC_9OE1atJ6aWz47/view?usp=sharing) |
| FER+ CNN Model              | [Google Drive Link ğŸ”—](https://drive.google.com/file/d/1NrzpxEtkK9DQywLU6WIyQIq1PduoQ6YH/view?usp=sharing) |
| RAF-DB CNN Model            | [Google Drive Link ğŸ”—](https://drive.google.com/file/d/1eCU5I_dZkgDOwA39NscJqDJqlCXU2LJD/view?usp=sharing) |
| Meta Classifier V2 Model  | [Google Drive Link ğŸ”—](https://drive.google.com/file/d/1MxfpNEAxYssJiE3nTkaxl_RKCL64U7_c/view?usp=sharing) |

> Place all models inside a `models/` directory or update their load paths in the notebook.

---

## ğŸ“ Requirements

Works in Google Colab or any Jupyter-based Python environment.

**Core Libraries:**

- `TensorFlow`, `Keras`
- `Transformers` (Hugging Face)
- `Gradio`
- `NumPy`, `Pandas`, `matplotlib`, `seaborn`, `scikit-learn`

Install missing packages in Colab:

```python
!pip install gradio transformers seaborn
```

## ğŸ¯ Applications

- Social media emotion & sentiment analysis
- Mental health signal detection
- Affective computing
- Digital wellness tools
- Content moderation and trend analysis

## ğŸ‘¤ Author

**Brendon Vineyard**

Capstone Senior Project, SUNY Potsdam (Spring 2025)

Advisor: Dr. Laura Grabowski

ğŸ“§ Email: brendonvineyard1@gmail.com

*This project fulfills the requirements of CIS 480: Senior Project in Computer Science at SUNY Potsdam.*

