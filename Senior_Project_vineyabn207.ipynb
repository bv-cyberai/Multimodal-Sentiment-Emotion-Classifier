{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3YR8FwiAR5H",
        "outputId": "185d0cfe-86ad-46c4-d9e7-14445bbb052f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training data shape: (28709, 48, 48, 1)\n",
            "Test data shape: (7178, 48, 48, 1)\n",
            "Training labels shape: (28709,)\n",
            "Test labels shape: (7178,)\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import cv2\n",
        "\n",
        "# Path to the extracted FER-2013 dataset\n",
        "dataset_folder = '/content/fer-2013'\n",
        "\n",
        "# Paths to the train and test folders\n",
        "train_folder = os.path.join(dataset_folder, 'train')\n",
        "test_folder = os.path.join(dataset_folder, 'test')\n",
        "\n",
        "# Initialize lists for image data and labels\n",
        "train_images = []\n",
        "train_labels = []\n",
        "test_images = []\n",
        "test_labels = []\n",
        "\n",
        "# Define the emotion labels\n",
        "emotion_labels = {\n",
        "    0: 'angry',\n",
        "    1: 'disgust',\n",
        "    2: 'fear',\n",
        "    3: 'happy',\n",
        "    4: 'sad',\n",
        "    5: 'neutral',\n",
        "    6: 'surprise'\n",
        "}\n",
        "\n",
        "def load_images_from_folder(folder, label):\n",
        "  # Initialize lists for image data and labels\n",
        "  images = []\n",
        "  labels = []\n",
        "\n",
        "  # Loop through the images in each emotion folder\n",
        "  for filename in os.listdir(folder):\n",
        "    img_path = os.path.join(folder, filename)\n",
        "    if filename.endswith('.jpg'): # Only load .jpg images\n",
        "      img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
        "      if img is not None:\n",
        "        # Resize image to 48x48 pixels (standard for FER-2013)\n",
        "        img = cv2.resize(img, (48, 48))\n",
        "        images.append(img)\n",
        "        labels.append(label)\n",
        "  return images, labels\n",
        "\n",
        "# Load images for each emotion category (train)\n",
        "for label in range(7):  # There are 7 emotion labels in FER-2013\n",
        "  emotion_folder = os.path.join(train_folder, emotion_labels[label])\n",
        "  images, labels = load_images_from_folder(emotion_folder, label)\n",
        "  train_images.extend(images)\n",
        "  train_labels.extend(labels)\n",
        "\n",
        "# Load images for each emotion category (test)\n",
        "for label in range(7):  # There are 7 emotion labels in FER-2013\n",
        "  emotion_folder = os.path.join(test_folder, emotion_labels[label])\n",
        "  images, labels = load_images_from_folder(emotion_folder, label)\n",
        "  test_images.extend(images)\n",
        "  test_labels.extend(labels)\n",
        "\n",
        "# Convert lists to numpy arrays\n",
        "X_train = np.array(train_images)\n",
        "y_train = np.array(train_labels)\n",
        "X_test = np.array(test_images)\n",
        "y_test = np.array(test_labels)\n",
        "\n",
        "# Normalize image data to [0, 1]\n",
        "X_train = X_train.astype('float32') / 255.0\n",
        "X_test = X_test.astype('float32') / 255.0\n",
        "\n",
        "# Reshape images to include a single channel for grayscale (48x48x1)\n",
        "X_train = X_train.reshape(-1, 48, 48, 1)\n",
        "X_test = X_test.reshape(-1, 48, 48, 1)\n",
        "\n",
        "# Verify the data shape\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Test data shape: {X_test.shape}\")\n",
        "print(f\"Training labels shape: {y_train.shape}\")\n",
        "print(f\"Test labels shape: {y_test.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiQ-Mx7rd4WA"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load Sentiment140 CSV file\n",
        "file_path = '/content/sentiment140/training.1600000.processed.noemoticon.csv'\n",
        "data = pd.read_csv(file_path, encoding='ISO-8859-1', header=None)\n",
        "\n",
        "# The dataset contaings columns:\n",
        "# 0 - sentiment label (0 for negative, 4 for positive)\n",
        "#"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4tuFDS_neoWK",
        "outputId": "67481be0-66ce-4398-b2ca-83366a28e09c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "   sentiment          id                          date     query  \\\n",
            "0          0  1467810369  Mon Apr 06 22:19:45 PDT 2009  NO_QUERY   \n",
            "1          0  1467810672  Mon Apr 06 22:19:49 PDT 2009  NO_QUERY   \n",
            "2          0  1467810917  Mon Apr 06 22:19:53 PDT 2009  NO_QUERY   \n",
            "3          0  1467811184  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
            "4          0  1467811193  Mon Apr 06 22:19:57 PDT 2009  NO_QUERY   \n",
            "\n",
            "              user                                               text  \n",
            "0  _TheSpecialOne_  witchfoot  - A that's a bummer.  You shoulda g...  \n",
            "1    scotthamilton  is upset that he can't update his Facebook by ...  \n",
            "2         mattycus  enichan I dived many times for the ball. Manag...  \n",
            "3          ElleCTF    my whole body feels itchy and like its on fire   \n",
            "4           Karoli  ationwideclass no, it's not behaving at all. i...  \n",
            "Training data shape: (1280000,)\n",
            "Test data shape: (320000,)\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import re\n",
        "\n",
        "# Load Sentiment140 CSV file\n",
        "file_path = '/content/sentiment140/training.1600000.processed.noemoticon.csv'\n",
        "data = pd.read_csv(file_path, encoding='ISO-8859-1', header=None)\n",
        "\n",
        "# Add proper column names\n",
        "data.columns = ['sentiment', 'id', 'date', 'query', 'user', 'text']\n",
        "\n",
        "# Clean the tweet text\n",
        "def clean_text(text):\n",
        "  # Remove URLS, mentions (@user), and extra spaces\n",
        "  text = re.sub(r'http\\S+|www\\S+|https\\S+', '', text)   # Remove URLS\n",
        "  text = re.sub(r'@\\w', '', text)   # Remove mentions (@user)\n",
        "  text = re.sub(r'\\s', ' ', text)   # Remove extra spaces\n",
        "  return text\n",
        "\n",
        "# Apply cleaning function\n",
        "data['text'] = data['text'].apply(clean_text)\n",
        "\n",
        "# Now, the dataset is cleaned, and you can split it into training and testing sets\n",
        "X = data['text']\n",
        "y = data['sentiment']\n",
        "\n",
        "# Split into train and tests sets (80% training, 20% testing)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Check the first few rows of the cleaned data\n",
        "print(data.head())\n",
        "\n",
        "# Check the shape of the datasets\n",
        "print(f\"Training data shape: {X_train.shape}\")\n",
        "print(f\"Test data shape: {X_test.shape}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nZDYEs4jlGGs",
        "outputId": "b1a2471f-d684-448f-9f22-8845ac6a8bde"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From <ipython-input-31-20dc341cc225>:6: is_gpu_available (from tensorflow.python.framework.test_util) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.config.list_physical_devices('GPU')` instead.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.18.0\n",
            "Is GPU available for TensorFlow? False\n",
            "PyTorch version: 2.5.1+cu124\n",
            "Is GPU available for PyTorch? False\n",
            "Number of GPUs available: 0\n",
            "No GPU found.\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "# Check TensorFlow GPU support\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Is GPU available for TensorFlow?\", tf.test.is_gpu_available())\n",
        "\n",
        "# Check PyTorch GPU support\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"Is GPU available for PyTorch?\", torch.cuda.is_available())\n",
        "\n",
        "# Check the number of GPUs available (if multiple GPUs are supported)\n",
        "print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
        "\n",
        "# Display GPU details for PyTorch\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU Name:\", torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    print(\"No GPU found.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6jDxC_5ZlmDx",
        "outputId": "5d40b59f-d6a5-42b3-dd68-7ca9ece17603"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "TensorFlow version: 2.18.0\n",
            "Is GPU available for TensorFlow? [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
            "PyTorch version: 2.5.1+cu124\n",
            "Is GPU available for PyTorch? True\n",
            "Number of GPUs available: 1\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "# Check TensorFlow GPU availability\n",
        "print(\"TensorFlow version:\", tf.__version__)\n",
        "print(\"Is GPU available for TensorFlow?\", tf.config.list_physical_devices('GPU'))\n",
        "\n",
        "# Check PyTorch GPU availability\n",
        "print(\"PyTorch version:\", torch.__version__)\n",
        "print(\"Is GPU available for PyTorch?\", torch.cuda.is_available())\n",
        "print(\"Number of GPUs available:\", torch.cuda.device_count())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4xvks8Lcl20p",
        "outputId": "0f145969-624c-413f-e700-9aff1dc75ba5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "No TPU found\n"
          ]
        }
      ],
      "source": [
        "# Check TensorFlow TPU availability\n",
        "try:\n",
        "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # Detect TPUs\n",
        "    print(\"TPU found\")\n",
        "except ValueError:\n",
        "    print(\"No TPU found\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d3F-cIeWmZoB",
        "outputId": "8b3c9052-8ec4-44e0-f890-5a4922924af3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Is GPU available for PyTorch? True\n",
            "GPU count: 1\n",
            "Current GPU: 0\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "print(\"Is GPU available for PyTorch?\", torch.cuda.is_available())\n",
        "print(\"GPU count:\", torch.cuda.device_count())\n",
        "print(\"Current GPU:\", torch.cuda.current_device())\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
